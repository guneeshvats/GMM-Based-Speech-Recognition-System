{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F25qTV4ubyia",
        "outputId": "93b90c04-1c8c-4540-fffc-478a7d93bfdd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install joblib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B71xypRIcBPk",
        "outputId": "6c1f5698-9e71-498a-9413-aee11d1b02a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import os\n",
        "import glob\n",
        "import librosa\n",
        "import scipy.io.wavfile as wave\n",
        "from scipy.fftpack import fft, ifft, fftshift\n",
        "import matplotlib.pyplot as plt \n",
        "import numpy as np\n",
        "from sklearn import mixture\n",
        "import joblib"
      ],
      "metadata": {
        "id": "NVdFP6c9b69b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ICAHVdIxb7AL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def traininig(train_data_path,feat_train_path,trained_model_path):\n",
        "  all_speakers=glob.glob(train_data_path+'*')\n",
        "  directory=feat_train_path\n",
        "  if not os.path.exists(directory):\n",
        "      os.makedirs(directory)\n",
        "      \n",
        "  directory=trained_model_path\n",
        "  if not os.path.exists(directory):\n",
        "      os.makedirs(directory)\n",
        "\n",
        "      \n",
        "  for itr1 in range(0,len(all_speakers)):\n",
        "      \n",
        "      wavs=glob.glob(all_speakers[itr1]+'/*.wav')\n",
        "      \n",
        "      spk=(all_speakers[itr1]).split(\"/\")[-1]\n",
        "      \n",
        "      if not os.path.exists(directory):\n",
        "          os.makedirs(directory)\n",
        "      \n",
        "      final_feat=np.empty([0, 39])\n",
        "      \n",
        "      for itr2 in range(0,len(wavs)):\n",
        "          \n",
        "          y, srr = librosa.load(wavs[itr2])\n",
        "          y = librosa.resample(y, srr, sr)\n",
        "          # sr=8000\n",
        "          \n",
        "          # hop_length=int(0.005*sr)\n",
        "          mfcc = librosa.feature.mfcc(y=y, sr=sr, hop_length=hop_length, n_mfcc=13)\n",
        "          mfcc_delta = librosa.feature.delta(mfcc)\n",
        "          mfcc_ddelta = librosa.feature.delta(mfcc_delta)\n",
        "          feat=np.concatenate((mfcc,mfcc_delta,mfcc_ddelta),axis=0)\n",
        "          feat=feat.transpose()\n",
        "          \n",
        "          final_feat=np.concatenate((final_feat,feat),axis=0)\n",
        "          \n",
        "\n",
        "          #print(final_feat.shape)\n",
        "      print(spk)    \n",
        "      np.savetxt(feat_train_path+spk+\"_all_features.txt\", final_feat, delimiter=\",\")\n",
        "\n",
        "      try:\n",
        "          gmm = mixture.GaussianMixture(n_components=n_mixtures, covariance_type='diag' , max_iter = max_iterations ).fit(final_feat)\n",
        "      except:\n",
        "          print(\"ERROR : Error while training model for file \"+spk)\n",
        "          \n",
        "      try:\n",
        "          joblib.dump(gmm,trained_model_path+spk+'.pkl')\n",
        "      except:\n",
        "          print(\"ERROR : Error while saving model for \"+spk)\n",
        "          \n",
        "\n",
        "  print(\"Training Completed\")\n"
      ],
      "metadata": {
        "id": "zHptFw0Gb7Cq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def testing(test_data_path,feat_test,trained_model_path):\n",
        "    # train feature extraction\n",
        "  all_speakers=glob.glob(test_data_path+'*')\n",
        "\n",
        "  import os\n",
        "  directory=feat_test\n",
        "  if not os.path.exists(directory):\n",
        "      os.makedirs(directory)\n",
        "\n",
        "  speakers = { all_speakers[k]:k for k in range(len(all_speakers)) }\n",
        "\n",
        "  num_test_cases={}\n",
        "  tct={}\n",
        "  for e in speakers:\n",
        "      num_test_cases[e.replace(test_data_path,'')]=len(os.listdir(e))-1\n",
        "      tct[e.replace(test_data_path,'')]=0\n",
        "\n",
        "  print(num_test_cases)\n",
        "\n",
        "  spk_names = { all_speakers[k].replace(test_data_path,''):k for k in range(len(all_speakers)) }\n",
        "\n",
        "  total_speakers=len(num_test_cases)\n",
        "\n",
        "  confusion_matrix = np.zeros((total_speakers,total_speakers))\n",
        "\n",
        "\n",
        "  for itr1 in range(0,len(all_speakers)):\n",
        "      \n",
        "      wavs=glob.glob(all_speakers[itr1]+'/*.wav')\n",
        "      \n",
        "      spk=(all_speakers[itr1]).split(\"/\")[-1]\n",
        "      \n",
        "      if not os.path.exists(directory):\n",
        "          os.makedirs(directory)\n",
        "      \n",
        "      final_feat=np.empty([0, 39])\n",
        "      \n",
        "      for itr2 in range(0,len(wavs)):\n",
        "          #print(wavs[itr2])\n",
        "          \n",
        "          y, srr = librosa.load(wavs[itr2])\n",
        "          y = librosa.resample(y, srr, sr)\n",
        "          # sr=8000\n",
        "\n",
        "          mfcc = librosa.feature.mfcc(y=y, sr=sr, hop_length=hop_length, n_mfcc=13,win_length=int(0.025*sr))\n",
        "          mfcc_delta = librosa.feature.delta(mfcc)\n",
        "          mfcc_ddelta = librosa.feature.delta(mfcc_delta)\n",
        "          feat=np.concatenate((mfcc,mfcc_delta,mfcc_ddelta),axis=0)\n",
        "          feat=feat.transpose()\n",
        "          \n",
        "          final_feat=np.concatenate((final_feat,feat),axis=0)\n",
        "\n",
        "          #print(final_feat.shape)\n",
        "          max_score=-np.inf\n",
        "          max_spk_name=\"\"\n",
        "          \n",
        "          for modelfile in sorted(glob.glob(trained_model_path+'*.pkl')):\n",
        "              gmm = joblib.load(modelfile) \n",
        "              score=gmm.score(feat)\n",
        "              #print score\n",
        "              if score>max_score:\n",
        "                  max_score,max_spk_name=score,modelfile.replace(trained_model_path,'').replace('.pkl','')\n",
        "\n",
        "          print(spk+\" -> \"+max_spk_name+(\" Y\" if spk==max_spk_name  else \" N\"))\n",
        "\n",
        "          confusion_matrix[ spk_names[spk] ][spk_names[max_spk_name]]+=1\n",
        "          tct[spk]+=1\n",
        "\n",
        "          \n",
        "      #print(spk)\n",
        "      np.savetxt(feat_test+spk+\"_all_features.txt\", feat, delimiter=\",\")\n",
        "  return tct,confusion_matrix,total_speakers\n",
        "      "
      ],
      "metadata": {
        "id": "GHjmJwBgb7FR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YSoKd5sCb7Hx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# All paths should be changed according to your file locations\n",
        "\n",
        "feat='/content/gdrive/MyDrive/speaker_recognition/sir_spk_rec/Spk_Rec/feat/'\n",
        "feat_train='/content/gdrive/MyDrive/speaker_recognition/sir_spk_rec/Spk_Rec/feat/train/'\n",
        "feat_test='/content/gdrive/MyDrive/speaker_recognition/sir_spk_rec/Spk_Rec/feat/test/'\n",
        "trained_model='/content/gdrive/MyDrive/speaker_recognition/sir_spk_rec/Spk_Rec/train_models/'\n",
        "train_data='/content/gdrive/MyDrive/speaker_recognition/sir_spk_rec/Spk_Rec/SPK_DATA/traindata/'\n",
        "test_data='/content/gdrive/MyDrive/speaker_recognition/sir_spk_rec/Spk_Rec/SPK_DATA/testdata/'"
      ],
      "metadata": {
        "id": "tuTj8BLdb7Ka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for removing existing feature folders, models created\n",
        "if os.path.exists('/content/gdrive/MyDrive/speaker_recognition/sir_spk_rec/Spk_Rec/feat/'):\n",
        "  !rm -rf '/content/gdrive/MyDrive/speaker_recognition/sir_spk_rec/Spk_Rec/feat/'\n",
        "if os.path.exists('/content/gdrive/MyDrive/speaker_recognition/sir_spk_rec/Spk_Rec/train_models/'):\n",
        "  !rm -rf '/content/gdrive/MyDrive/speaker_recognition/sir_spk_rec/Spk_Rec/train_models/'"
      ],
      "metadata": {
        "id": "T7E1CJN2chG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "n_mixtures = 32\n",
        "max_iterations = 200\n",
        "calc_deltas=True\n",
        "sr=8000\n",
        "hop_length=int(0.005*sr)"
      ],
      "metadata": {
        "id": "E4JbTtLPb7My"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "traininig(train_data,feat_train,trained_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbqVrNIPb7Pa",
        "outputId": "b3a68c8d-9eed-43eb-b5cb-bd66e022b7dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fjlg0\n",
            "falk0\n",
            "fgcs0\n",
            "fgrw0\n",
            "fdjh0\n",
            "fcmg0\n",
            "fjlr0\n",
            "fdfb0\n",
            "fcke0\n",
            "feme0\n",
            "Training Completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tt,conf_mat,tot_spek=testing(test_data,feat_test,trained_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gp9bzeQPb7Rx",
        "outputId": "09ac3c6f-f998-4fc5-e466-aee7813ec29b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'fgcs0': 1, 'falk0': 1, 'fjlg0': 1, 'fcmg0': 1, 'fdjh0': 1, 'fgrw0': 1, 'fcke0': 1, 'fjlr0': 1, 'fdfb0': 1, 'feme0': 1}\n",
            "fgcs0 -> fgcs0 Y\n",
            "fgcs0 -> fgcs0 Y\n",
            "falk0 -> falk0 Y\n",
            "falk0 -> falk0 Y\n",
            "fjlg0 -> fjlg0 Y\n",
            "fjlg0 -> fjlg0 Y\n",
            "fcmg0 -> fcmg0 Y\n",
            "fcmg0 -> fcmg0 Y\n",
            "fdjh0 -> fdjh0 Y\n",
            "fdjh0 -> fdjh0 Y\n",
            "fgrw0 -> fgrw0 Y\n",
            "fgrw0 -> fgrw0 Y\n",
            "fcke0 -> fcke0 Y\n",
            "fcke0 -> fcke0 Y\n",
            "fjlr0 -> fjlr0 Y\n",
            "fjlr0 -> fjlr0 Y\n",
            "fdfb0 -> fdfb0 Y\n",
            "fdfb0 -> fdfb0 Y\n",
            "feme0 -> feme0 Y\n",
            "feme0 -> feme0 Y\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tt)\n",
        "print(\"Confusion Matrix:\\n\",conf_mat)\n",
        "print(\"Accuracy: \",(sum([ conf_mat[i][j] if i==j  else 0 for i in range(tot_spek) for j in range(tot_spek) ] )*100)/float(sum([i for i in tt.values()])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nGCY7Mhb7UD",
        "outputId": "411902d0-3498-444e-8b9d-a95d35dbc183"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'fgcs0': 2, 'falk0': 2, 'fjlg0': 2, 'fcmg0': 2, 'fdjh0': 2, 'fgrw0': 2, 'fcke0': 2, 'fjlr0': 2, 'fdfb0': 2, 'feme0': 2}\n",
            "Confusion Matrix:\n",
            " [[2. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 2. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 2. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 2. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 2. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 2. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 2. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 2. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 2. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 2.]]\n",
            "Accuracy:  100.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BQaZMx_tb7W7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EM8PwI-jb7ZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BeCeaaZxb7bb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "stnQMNgUb7dx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kvOpMToWb7gj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nApoTtBkb7jh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}